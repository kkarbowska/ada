---
title: "Analiza Danych Ankietowych, Sprawozdanie 1"
lang: pl
author: "Katarzyna Karbowska, Maciej Ostapiuk"
format: pdf
editor: visual
---

```{r}
#| echo: false
#| warning: false
library(tidyverse)
library(likert)
library(here)
library(ggmosaic)
library(binom)
library(stats)
library(binomCI)
```

# 1. Wstęp

## 1.1. Opis danych

Analizowany zbiór danych został zadany przez prowadzącego wykład "Analiza Danych Ankietowych". Dane dotyczą ankiety przeprowadzonej w pewnej dużej agencji reklamowej, która miała na celu ocenę satysfakcji z pracy. Wiadomo że w ankiecie wzięło udział dwieście losowo wybranych osób. W tym zestawie znajduje się osiem następujących zmiennych, będących odpowiedziami na poszczególne pytania:

-   **DZIAŁ** - jest odpowiedzią na pytanie "W jakim dziale jesteś zatrudniony", przyjmuje wartości **HR** (Dział obsługi kadrowo-płacowej), **IT** (Dział utrzymania sieci i systemów informatycznych), **DK** (Dział Kreatywny) lub **DS** (Dział Strategii)

-   **STAŻ** - zmienna odpowiadająca na pytanie "Jak długo pracujesz w firmie?", przyjmująca wartości **1** (poniżej 1 roku), **2** (Między jednym rokiem a trzema latami), **3** (Powyżej trzech lat)

-   **CZY_KIER** - zmienna będąca odpowiedzią na pytanie "Czy pracujesz na stanowisku menedżerskim?", przyjmująca wartości **Tak** (osoba jest na stanowisku menedżerskim) lub **Nie** (osoba obejmuje inne stanowisko niż menedżerskie)

-   **PYT_1 -** stanowi odpowiedź na pytanie "Jak bardzo zgadzasz się ze stwierdzeniem, że firma pozwala na elastyczne godziny pracy tym samym umożliwiając zachowanie równowagi między pracą a życiem prywatnym?", przyjmuje wartości: **-2** (zdecydowanie się nie zgadzam), **-1** (nie zgadzam się), **0** (nie mam zdania), **1** (zgadzam się), **2** (zdecydowanie się zgadzam)

-   **PYT_2** - odpowiada zadane pytanie "Jak bardzo zgadzasz się ze stwierdzeniem, że twoje wynagrodzenie adekwatnie odzwierciedla zakres wykonywanych przez ciebie obowiązków? i przyjmuje odpowiednie wartości **-2** (zdecydowanie się nie zgadzam), **-1** (nie zgadzam się), **1** (zgadzam się), **2** (zgadzam się)

-   **WIEK** - oznacza wiek respondenta

-   **PŁEĆ** - wskazuje na płeć ankietowanego

-   **PYT_3** - jest odpowiedzią dotyczącą wynagrodzenia z pracy, po rewizji wynagrodzeń, w której część pracowników otrzymało podwyżki

# 2. Wykonanie zadań z części I

## 2.1. Zadanie 1.1

**Wczytaj dane i przygotuj je do analizy. Zadbaj o odpowiednie typy zmiennych, zweryfikuj czy przyjmują wartości zgodne z powyższym opisem, zbadaj czy nie występują braki w danych.**

```{r}
#| echo: false
#| warning: false
katalog = dirname(normalizePath(file.choose())) # wybiera sie plik na którym chcemy pracować i najlepiej ten w którym są dane
setwd(katalog)
```

```{r}
#| warning: false
data <- read.csv("ankieta.csv", sep = ';', 
                 col.names = c('DZIAL', 'STAZ', 
                               'CZY_KIER', 'PYT_1', 
                               'PYT_2', 'PYT_3', 
                               'PLEC', 'WIEK'))
```

Sprawdźmy teraz czy wartości w kolumnach są przyjmowane wedle opisu tabeli.

```{r}
#| warning: false
sort(unique(data$DZIAL))    
sort(unique(data$STAZ))     
unique(data$CZY_KIER)      
sort(unique(data$PYT_1))  
sort(unique(data$PYT_2))
```

Widzimy, że zmienne przyjmują wartości zgodne z opisem. Zobaczmy teraz na ilość braków danych w poszczególnych kolumnach.

```{r}
#| warning: false
data %>% sapply(function(x) sum(is.na(x)))
```

Nie mamy żadnych braków w danych. Pozostaje nam sprawdzić jeszcze typy danych.

```{r}
#| warning: false
str(data)
```

Zauważmy, że zmienne DZIAŁ, STAŻ, CZY_KIER, PYT_1, PYT_2, PYT_3, PLEC zgodnie z opisem danych są zmiennymi kategorycznymi, typ zmiennych w zbiorze danych jest błędny i wymaga korekty.

```{r}
#| warning: false
data <- data %>%
  mutate_at(vars(DZIAL, STAZ, CZY_KIER, PYT_1, PYT_2, PYT_3, PLEC), as.factor)
```

## 2.2. Zadanie 1.2

**Utwórz zmienną *WIEK_KAT* przeprowadzając kategoryzacje zmiennej WIEK korzysatając z następujących przedziałów: do 35 lat, między 36 a 45 lat, między 46 a 55 lat, powyżej 55 lat.**

```{r}
#| warning: false
przedzialy_wiekowe <- c(0, 35, 45, 55, Inf)
nazwy_kategori <- c("0-35", "36-45", "46-55", "55+")
data$WIEK_KAT <- cut(data$WIEK, przedzialy_wiekowe, labels = nazwy_kategori, include.lowest = TRUE)
```

## 2.3. Zadanie 1.3

**Sporządź tablice liczności dla zmiennych: *DZIAŁ*, *STAZ*, *CZY_KIER*, *PŁEC*, *WIEK_KAT***.

```{r}
#| warning: false
amount_dzial <- data %>% group_by(DZIAL) %>% summarise(ile = n())
amount_staz <- data %>% group_by(STAZ) %>% summarise(ile = n())
amount_czy_kier <- data %>% group_by(CZY_KIER) %>% summarise(ile = n())
amount_plec <- data %>% group_by(PLEC) %>% summarise(ile = n())
amount_wiek_kat <- data %>% group_by(WIEK_KAT) %>% summarise(ile = n())
```

Wykonane tablice liczności zamieszczono poniżej.

```{r}
#| warning: false
#| echo: false
# knitr::kable(amount_dzial)
knitr::kable(amount_dzial, 
             caption = 'Tablica liczności zmiennej DZIAŁ')

knitr::kable(amount_staz, 
             caption = 'Tablica liczności zmiennej STAŻ')

knitr::kable(amount_czy_kier, 
             caption = 'Tablica liczności zmiennej CZY_KIER')

knitr::kable(amount_plec, 
             caption = 'Tablica liczności zmiennej PŁEĆ')

knitr::kable(amount_wiek_kat, 
             caption = 'Tablica liczności zmiennej WIEK_KAT')
```

## 2.4. Zadanie 1.4

**Sporządź wykresy kołowe oraz wykresy słupkowe dla zmiennych: *PYT_1* oraz *PYT_2***.

Najpierw sporządźmy wykresy słupkowe. Mamy:

```{r}
#| warning: false
kolory <- c("#66c2a5", "#fc8d62", "#8da0cb", "#e78ac3", "#a6d854") 

# zmienna PYT_1
data %>% 
  ggplot(aes(x = factor(PYT_1), fill = factor(PYT_1))) +
  geom_bar(fill='#66c2a5') +
  xlab('Odpowiedzi') + 
  ylab('Liczba obserwacji') +
  ggtitle('Wykres słupkowy zmiennej PYT_1', 
          subtitle = '"Jak bardzo zgadzasz się ze stwierdzeniem, że firma pozwala na \nelastyczne godziny pracy tym samym umożliwiając \nzachowanie równowagi między pracą \na życiem prywatnym?"') +
  scale_x_discrete(labels = c("zdecydowanie się \n nie zgadzam", 
                              "nie zgadzam się", 
                              "nie mam zdania", 
                              "zgadzam się", 
                              "zdecydowanie \n się zgadzam"))

# zmienna PYT_2
data %>% 
  ggplot(aes(x = factor(PYT_2), fill = factor(PYT_2))) +
  geom_bar(fill='#66c2a5') +
  xlab('Odpowiedzi') + 
  ylab('Liczba obserwacji') +
  ggtitle('Wykres słupkowy zmiennej PYT_2', 
          subtitle = '"Jak bardzo zgadzasz się ze stwierdzeniem, że twoje wynagrodzenie \nadekwatnie odzwierciedla zakres wykonywanych \nprzez ciebie obowiązków?"') +
  scale_x_discrete(labels = c("zdecydowanie się \n nie zgadzam", 
                              "nie zgadzam się", 
                              "zgadzam się", 
                              "zdecydowanie \n się zgadzam"))
```

Następnie, podane wizualizacje przedstawmy w postaci wykresów kołowych.

```{r}
#| warning: false
data %>% 
    ggplot(aes(x = '', fill = factor(PYT_1))) +
    geom_bar(color = 'white') +
    scale_fill_manual(values = kolory,
                      name = 'Odpowiedzi',
                      labels = c("zdecydowanie się nie zgadzam", 
                                 "nie zgadzam się", 
                                 "nie mam zdania", 
                                 "zgadzam się", 
                                 "zdecydowanie się zgadzam")) +
    coord_polar('y', start = pi / 2) +
    labs(title = 'Wykres kołowy dla zmiennej PYT_1') +
    theme_void()
    

# zmienna PYT_2
data %>% 
  ggplot(aes(x = '', fill = factor(PYT_2))) +
  geom_bar(color = 'white') +
  scale_fill_manual(values = kolory,
                    name = 'Odpowiedzi',
                    labels = c("zdecydowanie się nie zgadzam", 
                               "nie zgadzam się", 
                               "zgadzam się", 
                               "zdecydowanie się zgadzam")) +
  coord_polar('y', start = pi / 2) +
  labs(title = 'Wykres kołowy dla zmiennej PYT_2') +
  theme_void()

```

## 2.5. Zadanie 1.5

**Sporządź tablice wielodzielcze dla par zmiennych: *PYT_1* i *DZIAL*, *PYT_1* i *STAŻ*, *PYT_1* i *CZY_KIER*, *PYT_1* i *PŁEC* oraz *PYT_1* i *WIEK_KAT***.

Wykonane tablice wielodzielcze dla zadanych par zmiennych znajdują się w poniższych tabelach.

```{r}
#| warning: false
crosstab_dzial_pyt1 <-table(data$DZIAL, data$PYT_1)
crosstab_staz_pyt1  <-table(data$STAZ, data$PYT_1)
crosstab_czy_kier_pyt1 <-table(data$CZY_KIER, data$PYT_1)
crosstab_plec_pyt1 <-table(data$PLEC, data$PYT_1)
crosstab_wiek_kat_pyt1 <-table(data$WIEK_KAT, data$PYT_1)
```

```{r}
#| warning: false
#| echo: false
# knitr::kable(crosstab_dzial_pyt1)
knitr::kable(crosstab_dzial_pyt1, 
             caption = 'Tablica wielodzielcza dla pary zmiennych PYT_1 i DZIAŁ')

knitr::kable(crosstab_staz_pyt1, 
             caption = 'Tablica wielodzielcza dla pary zmiennych PYT_1 i STAŻ')

knitr::kable(crosstab_czy_kier_pyt1, 
             caption = 'Tablica wielodzielcza dla pary zmiennych PYT_1 i CZY_KIER')

knitr::kable(crosstab_plec_pyt1, 
             caption = 'Tablica wielodzielcza dla pary zmiennych PYT_1 i CZY_KIER')

knitr::kable(crosstab_wiek_kat_pyt1, 
             caption = 'Tablica wielodzielcza dla pary zmiennych PYT_1 i WIEK_KAT')
```

## 2.6. Zadanie 1.6

**Sporządź tablice wielodzielczą dla pary zmiennych: *PYT_2* i *PYT_3.***

To zadanie rozwiązujemy podobnie, jak zadanie 5. Uzyskujemy:

```{r}
#| warning: false
crosstab_pyt2_pyt3 <-table(data$PYT_2, data$PYT_3)
knitr::kable(crosstab_pyt2_pyt3, 
             caption = 'Tablica wielodzielcza dla pary zmiennych PYT_2 i PYT_3')
```

## 2.7. Zadanie 1.7

**Utwórz zmienną *CZY_ZADOW* na podstawie zmiennej *PYT_2*, łącząc kategorie "nie zgadzam się" i "zdecydowanie się nie zgadzam" oraz "zgadzam się" i "zdecydowanie się zgadzam".**

W naszym podejściu zmienna ***CZY_ZADOW*** przyjmuje następujące wartości:

-   0 - osoba jest nie zadowolona

-   1 - osoba jest zadowowolona

```{r}
#| warning: false
data <- mutate(data, CZY_ZADOW = ifelse(as.numeric(as.character(PYT_2)) == -2, 0,
                                 ifelse(as.numeric(as.character(PYT_2)) == -1, 0,
                                 ifelse(as.numeric(as.character(PYT_2)) == 1, 1,
                          ifelse(as.numeric(as.character(PYT_2)) == 2, 1, "_")))))

data$CZY_ZADOW <- as.factor(as.integer(data$CZY_ZADOW))
```

## 2.8. Zadanie 1.8

**Sporządź wykresy mozaikowe odpowiadające parom zmiennych: *CZY_ZADOW* i *DZIAŁ*, *CZY_ZADOW* i *STAZ*, *CZY_ZADOW* i *CZY_KIER*, *CZY_ZADOW* i *PLEC* oraz *CZY_ZADOW* i *WIEK_KAT*. Czy na podstawie uzyskanych wykresów można postawić pewne hipotezy dotyczące relacji między powyższymi zmiennymi? Spróbuj sformułować kilka takich hipotez.**

### 1. Wykres mozaikowy pary zmiennych CZY_ZADOW i DZIAŁ

```{r}
#| warning: false
data %>% ggplot() +
  geom_mosaic(aes(x = product(CZY_ZADOW,DZIAL)), fill='#66c2a5') +
  ylab("Czy osoba jest zadowolona") + 
  xlab("Dział") + 
  ggtitle("Zadowolenie w zależności \nod działu ankietowanych osób") +
  theme_mosaic()
```

Zauważmy, że największy odsetek osób zadowolonych ze swojej sytuacji badanej w firmie przypada na dział IT. Nic w tym dziwnego - zarobki są atrakcyjne oraz sama praca z reguły jest dla osób, które w tej pracy lubią się spełniać - praca w dziale komunikacji jest łatwiej "dostępna" i osiągalna, co niesie za sobą ryzyko związane z tym, że ludzie tam pracujący nie robią tego z pasji.

### 2. Wykres mozaikowy pary zmiennych CZY_ZADOW i STAZ

```{r}
#| warning: false
data %>% ggplot() +
  geom_mosaic(aes(x = product(CZY_ZADOW, STAZ)), fill='#66c2a5') +
  ylab("Czy osoba jest zadowolona") + 
  xlab("Długość stażu") + 
  ggtitle("Zadowolenie w zależności od długości \nstażu ankietowanych osób") + 
  theme_mosaic()
```

Z kolei tutaj zauważamy największe zadowolenie wśród stażystów ze stażem w długości od roku do 3 lat. Jest to dosyć długi czas, jak na staż, jednakże może być to związane z poczuciem integralności w firmie, reputacja na swój temat oraz swojej pozycji w firmie rośnie. Stażyści powyżej 3 lat mają podzielone zdania- jest to już bardzo długi okres jeżeli chodzi o stanowiska stażowe, pracownicy z pewnością chcieliby zostać bardziej docenieni, bardziej poważani wśród innych pracowników.

### 3. Wykres mozaikowy pary zmiennych CZY_ZADOW i CZY_KIER

```{r}
#| warning: false
data %>% ggplot() +
  geom_mosaic(aes(x = product(CZY_ZADOW,CZY_KIER)), fill='#66c2a5') +
  ylab("Czy osoba jest zadwolona") + 
  xlab("Czy osoba jest kierownikiem") + 
  ggtitle("Zadowolenie w zależności od bycia na \nstanowisku kierowniczym \n wśród ankietowanych osób") +
  theme_mosaic()
```

Zdecydowanie widzimy wieksze, dominujące zadowolenie wśród pracowników niebędących kierownikami. Stanowiska kierownicze rządzą się oczywiście swoimi prawami, więc nie powinno to budzić wątpliwości.

### 4. Wykres mozaikowy pary zmiennych CZY_ZADOW i PLEC

```{r}
#| warning: false
data %>% ggplot() +
  geom_mosaic(aes(x = product(CZY_ZADOW,PLEC)), fill='#66c2a5') +
  ylab("Czy osoba jest zadowolona") + 
  xlab("Płeć") + 
  ggtitle("Zadowolenie w zależności od płci \nankietowanych osób") + 
  theme_mosaic() 
```

Jeżeli rozważymy zadowolenie w zależności od płci ankietowanych osób, to tutaj nie ma większych różnic. Zdecydowanie więcej ankietowanych to mężczyźni, jednakże odsetek osób zadowolonych wśród obu płci jest podobny. Można wnioskować o równym traktowaniu pracowników firmy.

### 5. Wykres mozaikowy pary zmiennych CZY_ZADOW i WIEK_KAT

```{r}
#| warning: false
data %>% ggplot() +
  geom_mosaic(aes(x = product(CZY_ZADOW,WIEK_KAT)), fill='#66c2a5') +
  ylab("Czy osoba jest zadwolona") + 
  xlab("Przedział wiekowy") + 
  ggtitle("Zadowolenie w zależności od wieku \nankietowanych osób") + 
  theme_mosaic() 
```

Największa ilość pracowników przypada na przedział wiekowy 36-45. Jednymi z najbardziej zadowolnych pracowników są ci w wieku 46-55.

Generalnie, ułożenie wykresów mozaikowych przeważnie sugeruje na pewne wzorce w zadowoleniu społeczeństwa. Najbardziej niezależnym aspektem jest płeć człowieka.

# 3. Wykonanie zadań z części II

## 3.1. Zadanie 2.

**Zapoznaj się z biblioteką likert i dostępnymi tam funkcjami summary oraz plot (wykresy typu "bar", "heat" oraz "density"), a następnie zilustruj odpowiedzi na pytanie "Jak bardzo zgadzasz się ze stwierdzeniem, że firma pozwala na (...)?" (zmienna PYT_1) w całej badanej grupie oraz w podgrupach ze względu na zmienna CZY_KIER.**

Pakiet likert służy do analizy danych zgromadzonych przy użyciu skali Likerta. Funkcja summaryw tej bibliotece daje krótkie podsumowanie zbioru danych. Zawiera nazwę danych których dotyczy analiza ("Item"), a także kolumnę "low" odpowiadającą za sumę odpowiedzi poniżej wartości neutralnej, kolumnę "high" odpowiadająca za sumę odpowiedzi poniżej wartości powyżej wartości neutralnej, oraz kolumny "średnia" i "sd" odpowiadające odpowiednio średniej i odchyleniu standardowemu. Poniżej znajduje się krótkie podsumowanie zmiennej PYT_1 wykonane funkcją summary.

```{r}
#| warning: false
likert_df = likert(data[,"PYT_1", drop=FALSE])
knitr::kable(summary(likert_df))
```

Przejdziemy teraz do z ilustrowania odpowiedzi na pytanie "Jak bardzo zgadzasz się ze stwierdzeniem, że firma pozwala na elastyczne godziny pracy tym samym umożliwiając zachowanie równowagi między pracą a życiem prywatnym?". Wykonaliśmy w tym celu wykresy typu "bar", "heat" oraz "density" dla zadanej zmiennej PYT_1. Wykres typu "bar" znajduję się poniżej. Zauważmy, że większość respontentów zgadza się ze stwierdzeniem że firma pozwala na elastyczne godziny pracy, tym samym umożliwiając zachowanie równowagi między pracą a życiem prywatnym. Zdecydowanie mniej bo aż tylko 16% nie opowiada się za tym zdaniem. Można przypuszczać, że pracownicy są zadowoleni z takiego trybu pracy.

```{r}
#| warning: false
plot(likert_df, type = 'bar', legend.position = 'right') +
  ylab('Wartość procentowa') +
  xlab(' ') +
  ggtitle('Wykres typu bar dla zmiennej PYT_1 (cała badana grupa)',
          subtitle = 'Jak bardzo zgadzasz się ze stwierdzeniem, że firma pozwala\n na elastyczne godziny pracy tym samym umożliwiając \n zachowanie równowagi między pracą a życiem prywatnym?') +
  scale_fill_manual(values = kolory,
                    name = 'Odpowiedzi',
                    labels = c("zdecydowanie się nie zgadzam", 
                               "nie zgadzam się", "nie mam zdania", 
                               "zgadzam się", 
                               "zdecydowanie się zgadzam"))
```

Na poniższym rysunku mamy wykres typu heat. Możemy poznać procentowy rozkład odpowiedzi na pytanie " Jak bardzo zgadzasz się ze stwierdzeniem, że firma pozwala na elastyczne godziny pracy, tym samym umożliwiając zachowanie równowagi między pracą a życiem prywatnym?". Możemy zauważyć tak jak na poprzednim wykresie, że pracownicy są zgodni z tym twierdzeniem. Dodatkowo mamy pokazaną średnią odpowiedzi, która wynosi 3,56.

```{r}
#| warning: false
plot(likert_df, type = 'heat', low.color = "#F3FFFB", high.color = "#66c2a5") + 
  ggtitle('Wykres typu heat dla zmiennej PYT_1 (cała badana grupa)',
          subtitle = '"Jak bardzo zgadzasz się ze stwierdzeniem,  że firma pozwala na elastyczne godziny pracy \n tym samym umożliwiając zachowanie równowagi między pracą a życiem prywatnym?"') +
  scale_y_discrete(labels = c("zdecydowanie się \n nie zgadzam", 
                              "nie zgadzam się", 
                              "nie mam zdania", 
                              "zgadzam się", 
                              "zdecydowanie \n się zgadzam", 
                              "Mean(SD)")) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

```

Poniższy wykres przedstawia rozkład zmiennej PYT_1. Podobnie jak w poprzednich wizualizacjach może wywnioskować, że jest więcej osób, które się zgadzają z stwierdzeniem.

```{r}
#| warning: false
plot(likert_df, type = 'density', facet=TRUE) +
  scale_x_continuous(breaks=c(1,2,3, 4, 5),
                     labels=c("zdecydowanie się \n nie zgadzam", 
                              "nie zgadzam się", 
                              "nie mam zdania", 
                              "zgadzam się", 
                              "zdecydowanie \n się zgadzam")) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```

W następnym kroku wykonaliśmy wykres typu "bar" dla analizowanej zmiennej PYT_1 z podziałem na podgrupy ze względu na zmienną CZY_KIER. Na poniższym diagramie mamy podział na osoby które są menadżerem ('TAK') oraz nie piastują tego stanowiska ('NIE'). Możemy zauważyć, że więcej pracowników firmy, którzy nie mają stanowiska menadżerskiego niż tych które je mają jest zadowolona z elastycznych godzin pracy. Może być to związane z tym, że menadżer posiada z pewnością obowiązków i granica pomiędzy życiem prywatnym a zawodowym może się zacierać.

```{r}
#| warning: false
subgroup_likert <- likert(data[,"PYT_1", drop=FALSE], grouping = data$CZY_KIER)

plot(subgroup_likert, type = "bar") +
  ylab('Wartość procentowa') +
  xlab('Podział na zmienną CZY_KIER') +
  ggtitle('Wykres typu heat dla zmiennej PYT_1 (podział na podgrupy)',
          subtitle = '"Jak bardzo zgadzasz się ze stwierdzeniem,  że firma pozwala na elastyczne godziny pracy \n tym samym umożliwiając zachowanie równowagi między pracą a życiem prywatnym?"') +
  scale_fill_manual(values = kolory,
                    name = 'Odpowiedzi',
                    labels = c("zdecydowanie się nie zgadzam", 
                               "nie zgadzam się", 
                               "nie mam zdania", 
                               "zgadzam się", 
                               "zdecydowanie się zgadzam")) + 
  theme(legend.position = 'right')
```

## 3.2. Zadanie 3.

**Zapoznaj sie z funkcją sample z biblioteki stats, a następnie wylosuj próbkę o liczności 10% wszystkich rekordów z pliku "ankieta.csv" w dwóch wersjach: ze zwracaniem oraz bez zwracania.**

Wylosowaliśmy próbkę o liczności 10% wszystkich rekordów z analizowanego zbioru danych w oby dwóch wersjach ze zwracaniem oraz bez zwracania, i wyświetliliśmy uzyskane wartości.

```{r}
#| warning: false
n <- nrow(data) * 0.1 # 10% z 200 
 
# losowanie bez zwracania
which_row_false <- sample(c(1:nrow(data)), size = n, replace = FALSE)
cat("Próbka wylosowana bez zwracania",which_row_false)
# view(data[which_row_false,]) - tak możemy wyświetlić dane o podanych indeksach

# losowanie ze zwracaniem 
which_row_true <- sample(c(1:nrow(data)), size = n, replace = TRUE)
cat("Próbka wylosowana ze zwracaniem",which_row_true)
```

W przypadku wyznaczonych danych przez indeksy wylosowane ze zwracaniem i bez zwracania wygląda to następująco.

```{r}
#| warning: false
#| echo: false

knitr::kable(data[which_row_false,], 
             caption = "Wylosowane rekordy bez zwracania")

knitr::kable(data[which_row_true,], 
             caption = "Wylosowane rekordy ze zwracaniem")
```

## 3.3. Zadanie 4.

**Zaproponuj metodę symulowania zmiennych losowych z rozkładu dwumianowego. Napisz funkcje do generowania realizacji, a nastepnie zaprezentuj jej działanie porównujac wybrane teoretyczne i empiryczne charakterystyki dla przykładowych wartosci paramertów rozkładu: n i p.**

Będziemy generować zmienne losowe z rozkładu dwumianowego, który jest postaci:

$$
P\{X=i\} =  {n \choose i}p^i(1-p)^{n-i} 
$$

wykorzystując metodę odwrotnej dystrybuanty. Dodatkowo będziemy kożystać z tożsamości rekurencyjnej tego rozkładu, która została sformułowana w odpowiedni sposób:

$$
P\{X=i+1\} =\frac{n-i}{i+1}\cdot \frac{p}{1-p} \cdot P\{X=i\}
$$

Algorytm generowania zmiennej losowej z rozkładu dwumianowego jest następujący. \[1\]

1.  Generujemy $U\sim U(0,1)$
2.  Ustawiamy $p_0 = (1-p)^n, F = p_0, c= \frac{p}{1-p}$
3.  Jeśli $U\leq F$ to zwróć $X = i$, w przeciwnym razie $p_0 = c\cdot (\frac{n-i}{i+1})\cdot p_0$, $F = F + p_0$
4.  Wróć do 3.

Poniższa implentacja korzysta powyższego algorytmu, aby wygenerować wektor zmiennych losowych.

```{r}
#| warning: false
set.seed(123)

generate_binom <- function(n, p, N=1000){
  U <- runif(N)
  p0 <- (1 - p)^n 
  Cprob <- p0
  
  for (i in 0:n) {
    if (i == 0) {
      U[U <= Cprob] <- n + 1
    } else if (i == 1) {
      U[U <= Cprob] <- n + 2
    } else {
      U[U <= Cprob] <- i
    }
    
    p0 <- ((n - i) / (i + 1)) * (p / (1 - p)) * p0
    Cprob <- Cprob + p0
  }
  
  U[U == n + 1] <- 0
  U[U == n + 2] <- 1
  
  return(U)}

```

Sprawdzimy działanie oraz poprawność generatora zmiennych losowych porównując charakterystyki rozkładu. Porównamy ze sobą dystrybuanty, gęstości, średnie i wariancje teoretyczne oraz empiryczne.

```{r}
#| warning: false
# funkcja do porównywania dystrybuant
comparison_cdfs_binom <- function(n=20, p, size=1000){
  
  sample <- generate_binom(n, p, size)
  empirical_cdf <- ecdf(sample)
  x_values <- 0:n
  
  plot(empirical_cdf, main = "Porównanie dystrybuant empirycznej z teoretyczną", 
       col = "blue", lwd = 2)
  curve(pbinom(x, n, p), add = TRUE, col = "red", lwd = 2, lty = 2, n = 1000)
  legend("bottomright", legend = c("Empiryczna", "Teoretyczna"), 
         col = c("blue", "red"), lty = 1:2, lwd = 2) }

# funkcja do porównywania gęstości  
comparison_pdfs_binom <- function(n, p, size=1000){
  sample <- generate_binom(n, p, size)
  x_values <- 0:n
  theoretical_prob <- dbinom(x_values, n, p)
  
  values <- unique(sample)
  counts <- table(sample)
  empirical_prob <- counts/size
  
  plot(empirical_prob, type = "p", col = "blue", pch = 16, ylim = c(0, max(max(empirical_prob), max(theoretical_prob)) + 0.05),
       xlab = "x", ylab = "Probability", main = "Porównanie rozkładów prawdopodobieństwa \n rozkład dwumianowy")
  points(x_values, theoretical_prob, col = "red", pch = 16)
  legend("topright", 
         legend = c("Empiryczny", "Teoretyczny"), 
         col = c("blue", "red"), 
         pch = 16)}

# funkcja do porównywania średniej
comparison_mean_binom <- function(n=20, p, size=1000){
  sample <- generate_binom(n, p, size)
 
  mean_empirical <- mean(sample)
  mean_theoretical <- n * p
  
  cat("\n\nŚrednia empiryczna:", mean_empirical, "\n")
  cat("Średnia teoretyczna:", mean_theoretical, "\n\n")
}

# funkcja do porównywania wariancji
comparison_var_binom <- function(n=20, p, size=1000){
  sample <- generate_binom(n, p, size)
  
  var_empirical <- var(sample)
  var_theoretical <- n * p * (1 - p)
  
  cat("Wariancja empiryczna:", var_empirical, "\n")
  cat("Wariancja teoretyczna:", var_theoretical, "\n")
}


```

Dla przykładu weźmiemy sobie rozkład o wartościach parametrów rozkładu $n = 20$ i $p = 0.1$.

```{r}
#| warning: false
comparison_cdfs_binom(n=20, 0.1, size=1000)
comparison_pdfs_binom(20, 0.1, size=1000)
comparison_mean_binom(20, 0.1, size=1000)
comparison_var_binom(20, 0.1, size=1000)

```

Zauważmy, że najważniejsze charakterystyki empiryczne i teoretyczne rozkładu są zbliżone do siebie, co wskazuje na poprawność generatora zmiennych losowych. Dodatkowo sprawdzimy naszą tezę, porównując poszczególne empiryczne prawdopodobieństwa z teoretycznymi zadanymi wartościami. Porównamy rozkłady o parametrach $p=\{0.1, 0.5, 0.9\}$.

```{r}
#| warning: false
empirical_p_binom <- function(n=20, p, size=1){
  sample <- generate_binom(n, p, size)
  l <- length(sample)
  p_empirical <- sum(sample)/(n*l)
  
  return(p_empirical)
}

theo_prob <- c(0.1, 0.5, 0.9)
emp_prob <- sapply(theo_prob, function(p) empirical_p_binom(p = p, size=1000))

```

Wyniki dokonane z porównania parametru prawdopodobieństwa zostaną umieszczone w poniższej tabeli.

```{r}
#| warning: false
compare_p <- data.frame(Wartosci_teoretyczne = theo_prob, 
                        Wartosci_empiryczne = emp_prob)
knitr::kable(compare_p)
```

Zauważmy że wartości empiryczne parametru p są dostatecznie bliskie wartościom teoretycznym co potwierdza naszą tezę o poprawności generatora zmiennych losowych.

## 3.4 Zadanie 5.

**Zaproponuj metodę symulowania wektorów losowych z rozkładu wielomianowego. Napisz funkcję do generowania realizacji, a następnie zaprezentuj jej działanie porównując wybrane teoretyczne i empiryczne charakterystyki dla przykładowych wartości paramertów rozkładu: n i p**

Metoda wykorzystana do implementacji znajduje się w publikacji \[2\] i opiera się na metodyce metody odwrotnej dystrybuanty.

```{r}
#| warning: false
simulateMultinomial <- function(n, probs, size) {
  res <- matrix(0, nrow = size, ncol = length(probs))
  for (k in 1:size) {
    probs <- probs / sum(probs)
    
    cumulativeProbs <- cumsum(probs)
    
    counts <- rep(0, length(probs))
    
    for (i in 1:n) {
      rand <- runif(1)
      
      for (j in 1:length(cumulativeProbs)) {
        if (rand <= cumulativeProbs[j]) {
          counts[j] <- counts[j] + 1
          break
        }
      }
    }
    res[k,] <- counts
  }
  res
}
```

W każdej iteracji zwracany jest indeks odpowiadający za moment, w którym skumulowane prawdopodobieństwo nie przekracza wartości zmiennej losowej z rozkładu $\mathcal{U}(0,1)$.

Do sprawdzenia poprawności estymatora wykorzystamy trzy przykładowe wektory prawdopodobieńśtw:${(0.1, 0.3, 0.4, 0.2), (0.5, 0.3, 0.2), (0.1, 0.1, 0.3, 0.2, 0.3)}$. Wykorzystamy również realizację 100 wartości wektorów losowych o zadanych wektorach prawdopodobieństw.

```{r}
#| warning: false
n = 100
probs_1 <- c(0.1, 0.3, 0.4, 0.2) 
probs_2 <- c(0.5, 0.3, 0.2)
probs_3 <- c(0.1, 0.1, 0.3, 0.2, 0.3)

sample_1 <- simulateMultinomial(n, probs_1, 1000)
sample_2 <- simulateMultinomial(n, probs_1, 1000)
sample_3 <- simulateMultinomial(n, probs_1, 1000)

estimated_probs_1 = colMeans(sample_1/n)
estimated_probs_2 = colMeans(sample_2/n)
estimated_probs_3 = colMeans(sample_3/n)

sprintf("Estymowany wektor (0.1, 0.3, 0.4, 0.2): (%s).", 
        toString(estimated_probs_1))
sprintf("Estymowany wektor (0.5, 0.3, 0.2): (%s).", 
        toString(estimated_probs_1))
sprintf("Estymowany wektor (0.1, 0.1, 0.3, 0.2, 0.3): (%s).", 
        toString(estimated_probs_1))
```

Zauważmy, że przy stosunkowo małej wielkości próbki można już zauważyć wyniki potwierdzające zdecydowanie poprawność zaimplementowanej metody.

# 4. Wykonanie zadań z części III i IV

## 4.1. Zadanie 6.

**Napisz funkcje do wyznaczania realizacji przedziału ufnosci Cloppera-Pearsona. Niech argumentem wejsciowym będzie poziom ufności, liczba sukcesów i liczba prób lub poziom ufnosci i wektor danych (funkcja powinna obsługiwać oba przypadki).**

```{r}
#| warning: false
clopper_pearson_confidence_interval <- function(confidence_level, 
                                                successes=NULL, trials=NULL,
                                                vector_data=NULL) {
  
  if (!is.null(vector_data)) {
    
    successes <- length(vector_data[vector_data == 1])
    trials <- length(vector_data)
  }
  alpha <- 1 - confidence_level
  lower_bound <- qbeta(alpha/2, successes, trials - successes + 1)
  upper_bound <- qbeta(1 - (alpha/2), successes + 1, trials - successes)
  
  return(c(lower_bound, upper_bound))
}
```

## 4.2. Zadanie 7.

**Korzystając z funkcji napisanej w zadaniu 6. wyznacz realizacje przedziałów ufności dla prawdopodobieństwa, że pracownik jest zadowolony z wynagrodzenia w pierwszym badanym okresie oraz w drugim badanym okresie. Skorzystaj ze zmiennych CZY_ZADW oraz CZY_ZADW_2 (utwórz zmienną analogicznie jak w zadaniu 1.7). Przyjmij** $1-\alpha = 0.95$.

Na wstępie utworzymy zmienną CZY_ZADOW_2 analogicznie jak tworzyliśmy zmienną CZY_ZADOW.

```{r}
#| warning: false
data <- mutate(data, CZY_ZADOW_2 = ifelse(as.numeric(as.character(PYT_3)) == -2, 0,
                                  ifelse(as.numeric(as.character(PYT_3)) == -1, 0,
                                  ifelse(as.numeric(as.character(PYT_3)) == 1, 1,
                          ifelse(as.numeric(as.character(PYT_3)) == 2, 1, "_")))))

data$CZY_ZADOW_2 <- as.factor(as.integer(data$CZY_ZADOW_2))
```

Najpierw wyznaczyliśmy realizacje przedziału ufności dla prawdopodobieństwa że pracownik jest zadowolony z wynagrodzenia w pierwszym badanym okresie.

```{r}
#| warning: false
num_czy_zadow <- length(data$CZY_ZADOW[data$CZY_ZADOW == 1])
cp_czy_zadow <- clopper_pearson_confidence_interval(confidence_level = 0.95,
                                                    successes = num_czy_zadow,
                                                    trials = nrow(data))
cat('[', paste(cp_czy_zadow, collapse = ', '), ']')
```

W kolejnym etapie wykonaliśmy tą samą czynność dla prawdopodobieństwa, że pracownik będzie zadowolony z wynagrodzenia w pierwszym drugim badanym okresie.

```{r}
#| warning: false
num_czy_zadow_2 <- data$CZY_ZADOW_2
cp_czy_zadow_2 <- clopper_pearson_confidence_interval(confidence_level = 0.95,
                                                      vector_data = num_czy_zadow_2)
cat('[', paste(cp_czy_zadow_2, collapse = ', '), ']')
```

Rozważając związek między przedziałami ufności dla prawdopodobieństwa zadowolenia pracowników z wynagrodzenia w pierwszym oraz w drugim badanym okresie, możemy zauważyć, że przedział ufności dla tego prawdopodobieństwa w drugim okresie jest przesunięty w prawo. Innymi słowy, estymowana wartość prawdopodobieństwa zadowolenia w drugim okresie jest większa. W konsekwencji, można stwierdzić, że rewizja wynagrodzeń pozywnie wpłynęła na odsetek zadowolonych z osób z wysokości płac.

## 4.3 Zadanie 9.

**Przeprowadź symulacje, których celem jest porównanie prawdopodobińestwa pokrycia i długości przedziałów ufności Cloppera-Pearsona, Walda i trzeciego dowolnego typu zaimplementowanego w funkcji binom.confint. Rozważ** $1-\alpha = 0.95$**, rozmiar próby** $n \in \{30, 100, 1000\}$ **i różne wartości prawdopodobieństwa p. Wyniki umieść na wykresach i sformułuj wnioski, które dla konkretnych danych ułatwia wybór konkretenego typu przedziału ufności.**

W porównaniu brały udział trzy konstrukcje przedziałów- Walda, Cloppera-Pearsona oraz Agrestiego-Coulla. Porównanie przeprowadziliśmy według poniższej procedury Monte Carlo

### ***Metoda Monte Carlo***

1.  Generujemy realizację przedziału $\mathcal{B}(n,p)$
2.  Dla wygenerowanej realizacji wyznaczamy wszystkie przedziały ufności
3.  Obliczamy średnią długość przedziału wraz z prawdopodobieństwem pokrycia przedziału
4.  Symulacje wykonujemy dla $p \in\{0.01, ..., 0.99\}$, $n \in\{30,100,1000\}$ $MCS = 1000$ razy.

Wyniki przedstawiliśmy na wykresach dla poszczególnych $n$ .

## $n$ =30

```{r}
#| warning: false
Wald_CI = function(X, n, size, alpha) {
  p_est <- sum(X)/(n*size)
  quantile <- qnorm(1-alpha/2, mean = 0, sd = 1)
  lower_bound <-p_est - quantile * sqrt(p_est * (1-p_est) / n)
  upper_bound <-p_est + quantile * sqrt(p_est * (1-p_est) / n)
  CI <- c(lower_bound, upper_bound)
  return(CI)
} 

p_s = seq(from=0.01, to= 0.99, length.out = 99)

wald_res_coverage_30 = rep(0,99)
wald_res_len_30 = rep(0,99)
for (i in 1:99) {
  temp_len = rep(0,1000)
  temp_coverage = rep(0,1000)
  for (mcs in 1:1000) {
    sample_binom = rbinom(n = 100, size = 30, prob = p_s[i])

    ci_wald = Wald_CI(sample_binom, n = 30, 100, alpha = 0.05)
    temp_len[mcs] <- ci_wald[2] - ci_wald[1]
    temp_coverage[mcs] <-sum(ci_wald[1] < sample_binom/30& sample_binom/30<ci_wald[2])/100
  }
  wald_res_len_30[i] <-  mean(temp_len)
  wald_res_coverage_30[i] <-  mean(temp_coverage)
}

cp_res_coverage_30 = rep(0,99)
cp_res_len_30 = rep(0,99)
for (i in 1:99) {
  temp_len = rep(0,1000)
  temp_coverage = rep(0,1000)
  for (mcs in 1:1000) {
    sample_binom = rbinom(n = 100, size = 30, prob = p_s[i])
    ci_cp = binom.confint(sample_binom, n = 30,alpha = 0.05, methods = "exact")
    temp_len[mcs] <- mean(ci_cp$upper- ci_cp$lower)
    temp_coverage[mcs] <-sum(mean(ci_cp$lower) < sample_binom/30& 
                               sample_binom/30<mean(ci_cp$upper))/100
  }
  cp_res_len_30[i] <-  mean(temp_len)
  cp_res_coverage_30[i] <-  mean(temp_coverage)
}


ac_res_coverage_30 = rep(0,99)
ac_res_len_30 = rep(0,99)
for (i in 1:99) {
  temp_len = rep(0,1000)
  temp_coverage = rep(0,1000)
  for (mcs in 1:1000) {
    sample_binom = rbinom(n = 100, size = 30, prob = p_s[i])
    ci_ac = binom.confint(sample_binom, n = 30,alpha = 0.05, methods = "agresti-coull")
    temp_len[mcs] <- mean(ci_ac$upper- ci_ac$lower)
    temp_coverage[mcs] <-sum(mean(ci_ac$lower) < sample_binom/30& 
                               sample_binom/30<mean(ci_ac$upper))/100
  }
  ac_res_len_30[i] <-  mean(temp_len)
  ac_res_coverage_30[i] <-  mean(temp_coverage)
}

```

```{r}
plot(p_s,wald_res_len_30, type = "l", frame = FALSE, pch = 19,
     col = "red",main="Średnia długość przedziału ufności, 
        n = 30, długość próbki = 100, 1000 MCS", 
     xlab = "p", 
     ylab = "średnia długość przedziału", 
     lty = 1, lwd = 2)

lines(p_s, cp_res_len_30, pch = 23, col = "blue", type = "l", 
      lty = 2, lwd = 2)

lines(p_s, ac_res_len_30, pch = 18, col = "green", type = "b", 
      lty = 3, lwd = 2)

legend("topright", legend = c("Wald CI", "C-P CI", "A-C CI"),
       col = c("red", "blue", "green"), lty = 1:3, cex = 0.8, xjust = 1)
```

```{r}
plot(p_s,wald_res_coverage_30, type = "l", frame = FALSE, pch = 19,
     col = "red",
     main="Prawdopodobieństwo pokrycia przedziału ufności, 
        n = 30, długość próbki = 100, 1000 MCS", xlab = "p", 
     ylab = "prawdopodobieństwo pokrycia", 
     lty = 1, lwd = 2,ylim = c(0.8,1))

lines(p_s, cp_res_coverage_30, pch = 23, col = "blue", type = "l", 
      lty = 2, lwd = 2)

lines(p_s, ac_res_coverage_30, pch = 18, col = "green", type = "b", 
      lty = 3, lwd = 2)

legend("topright", legend = c("Wald CI", "C-P CI", "A-C CI"),
       col = c("red", "blue", "green"), lty = 1:3, cex = 0.8, xjust = 1)
```

Za pomocą analogicznego kodu wykonujemy procedury oraz wykresy dla pozostałych wartości $n$

### $n = 100$

```{r}
#| echo: false
wald_res_coverage_100 = rep(0,99)
wald_res_len_100 = rep(0,99)
for (i in 1:99) {
  temp_len = rep(0,1000)
  temp_coverage = rep(0,1000)
  for (mcs in 1:1000) {
    sample_binom = rbinom(n = 100, size = 100, prob = p_s[i])
    ci_wald = Wald_CI(sample_binom, n = 100, 100, alpha = 0.05)
    temp_len[mcs] <- ci_wald[2] - ci_wald[1]
    temp_coverage[mcs] <-sum(ci_wald[1] < sample_binom/100& sample_binom/100<ci_wald[2])/100
  }
  wald_res_len_100[i] <-  mean(temp_len)
  wald_res_coverage_100[i] <-  mean(temp_coverage)
}





cp_res_coverage_100 = rep(0,99)
cp_res_len_100 = rep(0,99)
for (i in 1:99) {
  temp_len = rep(0,1000)
  temp_coverage = rep(0,1000)
  for (mcs in 1:1000) {
    sample_binom = rbinom(n = 100, size = 100, prob = p_s[i])
    ci_cp = binom.confint(sample_binom, n = 100,alpha = 0.05, methods = "exact")
    temp_len[mcs] <- mean(ci_cp$upper- ci_cp$lower)
    temp_coverage[mcs] <-sum(mean(ci_cp$lower) < sample_binom/100& sample_binom/100<mean(ci_cp$upper))/100
  }
  cp_res_len_100[i] <-  mean(temp_len)
  cp_res_coverage_100[i] <-  mean(temp_coverage)
}


ac_res_coverage_100 = rep(0,99)
ac_res_len_100 = rep(0,99)
for (i in 1:99) {
  temp_len = rep(0,1000)
  temp_coverage = rep(0,1000)
  for (mcs in 1:1000) {
    sample_binom = rbinom(n = 100, size = 100, prob = p_s[i])
    ci_ac = binom.confint(sample_binom, n = 100,alpha = 0.05, methods = "agresti-coull")
    temp_len[mcs] <- mean(ci_ac$upper- ci_ac$lower)
    temp_coverage[mcs] <-sum(mean(ci_ac$lower) < sample_binom/100& sample_binom/100<mean(ci_ac$upper))/100
  }
  ac_res_len_100[i] <-  mean(temp_len)
  ac_res_coverage_100[i] <-  mean(temp_coverage)
}
```

```{r}
#| echo: false
plot(p_s,wald_res_len_100, type = "l", frame = FALSE, pch = 19,
     col = "red",main="Średnia długość przedziału ufności, 
        n = 100, długość próbki = 100, 1000 MCS", xlab = "p", ylab = "średnia długość przedziału", 
     lty = 1, lwd = 2)

lines(p_s, cp_res_len_100, pch = 23, col = "blue", type = "l", 
      lty = 2, lwd = 2)

lines(p_s, ac_res_len_100, pch = 18, col = "green", type = "b", 
      lty = 3, lwd = 2)

legend("topright", legend = c("Wald CI", "C-P CI", "A-C CI"),
       col = c("red", "blue", "green"), lty = 1:3, cex = 0.8, xjust = 1)

```

```{r}
#| echo: false
plot(p_s,wald_res_coverage_100, type = "l", frame = FALSE, pch = 19,
     col = "red",main="Prawdopodobieństwo pokrycia przedziału ufności, 
        n = 100, długość próbki = 100, 1000 MCS", xlab = "p", ylab = "prawdopodobieństwo pokrycia", 
     lty = 1, lwd = 2,ylim = c(0.8,1))

lines(p_s, cp_res_coverage_100, pch = 23, col = "blue", type = "l", 
      lty = 2, lwd = 2)

lines(p_s, ac_res_coverage_100, pch = 18, col = "green", type = "b", 
      lty = 3, lwd = 2)

legend("topright", legend = c("Wald CI", "C-P CI", "A-C CI"),
       col = c("red", "blue", "green"), lty = 1:3, cex = 0.8, xjust = 1)
```

### $n=1000$

```{r}
#| warning: false
#| echo: false
wald_res_coverage_1000 = rep(0,99)
wald_res_len_1000 = rep(0,99)
for (i in 1:99) {
  temp_len = rep(0,1000)
  temp_coverage = rep(0,1000)
  for (mcs in 1:1000) {
    sample_binom = rbinom(n = 100, size = 1000, prob = p_s[i])
    ci_wald = Wald_CI(sample_binom, n = 1000, 100, alpha = 0.05)
    temp_len[mcs] <- ci_wald[2] - ci_wald[1]
    temp_coverage[mcs] <-sum(ci_wald[1] < sample_binom/1000& sample_binom/1000<ci_wald[2])/100
  }
  wald_res_len_1000[i] <-  mean(temp_len)
  wald_res_coverage_1000[i] <-  mean(temp_coverage)
}


cp_res_coverage_1000 = rep(0,99)
cp_res_len_1000 = rep(0,99)
for (i in 1:99) {
  temp_len = rep(0,1000)
  temp_coverage = rep(0,1000)
  for (mcs in 1:1000) {
    sample_binom = rbinom(n = 100, size = 1000, prob = p_s[i])
    ci_cp = binom.confint(sample_binom, n = 1000,alpha = 0.05, methods = "exact")
    temp_len[mcs] <- mean(ci_cp$upper- ci_cp$lower)
    temp_coverage[mcs] <-sum(mean(ci_cp$lower) < sample_binom/1000& sample_binom/1000<mean(ci_cp$upper))/100
  }
  cp_res_len_1000[i] <-  mean(temp_len)
  cp_res_coverage_1000[i] <-  mean(temp_coverage)
}

ac_res_coverage_1000 = rep(0,99)
ac_res_len_1000 = rep(0,99)
for (i in 1:99) {
  temp_len = rep(0,1000)
  temp_coverage = rep(0,1000)
  for (mcs in 1:1000) {
    sample_binom = rbinom(n = 100, size = 1000, prob = p_s[i])
    ci_ac = binom.confint(sample_binom, n = 1000,alpha = 0.05, methods = "agresti-coull")
    temp_len[mcs] <- mean(ci_ac$upper- ci_ac$lower)
    temp_coverage[mcs] <-sum(mean(ci_ac$lower) < sample_binom/1000& sample_binom/1000<mean(ci_ac$upper))/100
  }
  ac_res_len_1000[i] <-  mean(temp_len)
  ac_res_coverage_1000[i] <-  mean(temp_coverage)
}
```

### ***Fakt***

Zapoznając się z proponowanymi funkcjami do generowania realizacji przedziałów ufności, można zauważyć podejście do implementacji polegające na generowaniu przedziałów ufności z osobna dla każdej zmiennej z losowego i.i.d $(X_1, ..., X_k)$, $X_i \sim \mathcal{B}(n,p)$. Czas działania owych funkcji, który jest kluczowy przy korzystaniu z pakietu R, można zoptymalizować, opierając się na poniższym spostrzeżeniu:

***Lemat***

Niech $(X_1, ..., X_k)$ - ciąg zmiennych losowych i.i.d o rozkładzie $X_i\sim\mathcal{B}(n,p)$. Wtedy prawdziwe jest:

$$
\xi = \sum_{i=1}^{k}{X_i} \sim \mathcal{B}(kn, p)
$$

Interpretacja jest następująca - wykonujemy $k$-krotnie pewne doświadczenie, każde składające się z $n$ niezależnych od siebie prób Bernoulliego. wynik i-tego doświadczenia jest zmienną losową $X_i \sim \mathcal{B}(n,p)$. Skoro zatem wyniki poszczególnych doświadczeń są od siebie niezależne, to próby Bernoulliego pomiędzy poszczególnymi doświadczeniami są również niezależne. Można zatem interpretować tą sytuację jako jedno, "wielkie" doświadczenie opierające się na $kn$ próbach Bernoulliego z prawdopodobieństwem sukcesu w każdej z takich prób równym $p$.

Punktowy estymator proporcji wyrażony w języku zmiennych $X_i$ to po prostu:

$$
\displaystyle {\hat{p} = \frac{\sum_{i=1}^{k}X_i}{nk}}.
$$

Zatem, opierając się na implementacjach proponowanych funkcji, moglibyśmy liczyć tylko jedną realizację przedziałów ufności dla całego wektora losowego.

```{r}
#| warning: false
#| echo: false
plot(p_s,wald_res_len_1000, type = "l", frame = FALSE, pch = 19,
     col = "red",main="Średnia długość przedziału ufności, 
        n = 1000, długość próbki = 100, 1000 MCS", xlab = "p", 
     ylab = "średnia długość przedziału", 
     lty = 1, lwd = 2)

lines(p_s, cp_res_len_1000, pch = 23, col = "blue", type = "l", 
      lty = 2, lwd = 2)

lines(p_s, ac_res_len_1000, pch = 18, col = "green", type = "b", 
      lty = 3, lwd = 2)

legend("topright", legend = c("Wald CI", "C-P CI", "A-C CI"),
       col = c("red", "blue", "green"), lty = 1:3, cex = 0.8, xjust = 1)

```

```{r}
#| warning: false
#| echo: false
plot(p_s,wald_res_coverage_1000, type = "l", frame = FALSE, pch = 19,
     col = "red",main="Prawdopodobieństwo pokrycia przedziału ufności, 
        n = 1000, długość próbki = 100, 1000 MCS", xlab = "p", 
     ylab = "prawdopodobieństwo pokrycia", 
     lty = 1, lwd = 2,ylim = c(0.8,1))

lines(p_s, cp_res_coverage_1000, pch = 23, col = "blue", type = "l", 
      lty = 2, lwd = 2)

lines(p_s, ac_res_coverage_1000, pch = 18, col = "green", type = "b", 
      lty = 3, lwd = 2)

legend("topright", legend = c("Wald CI", "C-P CI", "A-C CI"),
       col = c("red", "blue", "green"), lty = 1:3, cex = 0.8, xjust = 1)
```

Wnioski są następujące - dla $n =100$ oraz $n=1000$, za sprawą zbieżności przedziałów według rozkładów oraz prawa wielkich liczb które prowadzą do twierdzeń granicznych, nie ma większych różnic zarówno w przypadku średnich długości przedziałów jak i prawdopodobieńśtwa pokrycia. Warto wspomnieć, że dla $n = 30$ oraz dla bardzo dużego zakresu wartości $p$, najwęższymi przedziałami są przedziały Agrestiego-Coulla. Odzwierciedla się to oczywiście w prawdopodobieństwie pokrycia, które naturalnie będzie niższe, ponieważ jest mniejsza szansa, aby proporcje "załapały się" do węższego przedziału. Ta tendencja, choć w mniejszym stopniu zauważalna, to ogólna koneksja pomiędzy prawdopodobieństwem pokrycia a średnią długością przedziałów ufności - dla dużych $n$ z racji tego, że przedziały są tak samo szerokie, szansa na to, by pokrywały badane przez nas wartości proporcji jest porównywalna.

# 5. Wykonanie zadań z części V

## 5.1. Zadanie 11.

**Dla danych z pliku "ankieta.csv" korzystając z funkcji z zadania 8., przyjmując** $1 - \alpha = 0.95$**, zweryfikuj następujęce hipotezy i sformułuj wnioski:**

### 1. Prawdopodobieństwo, że w firmie pracuje kobieta wynosi 0.5.

Wykonamy test dwumianowy dla prawdopodobieństwa sukcesu. Hipoteza zerowa zakłada, że prawdobodobieństwo, że w firmie pracuje kobieta wynosi 0.5, natomiast hipoteza alternatywna jest zaprzeczeniem hipotezy zerowej. Przyjmujemy poziom ufności 0.95. Zweryfikowaliśmy przedziały ufności i p-wartość by ocenić prawdziwość hipotezy zerowej. Wyniki są widoczne poniżej.

```{r}
#| warning: false
sum_woman_work <- length(data$PLEC[data$PLEC == "K"])
test_1 <- binom.test(sum_woman_work, nrow(data), p = 0.5, 
                     alternative = "two.sided")
cat('P - wartość wynosi:', test_1$p.value, 
    ', przedział ufności jest postaci: [', test_1$conf.int, ']')
```

Zauważmy że p-wartość jest dużo mniejsza od poziomu istotności alpha = 0.05, co jest przesłanką do odrzucenia hipotezy zerowej. Dodatkowo, jeśli spojrzymy na przedział ufności dla prawdopodobieństwa sukcesu, widzimy że p = 0.5 nie jest w tym przedziale, co potwierdza tezę o odrzuceniu hipotezy zerowej. Podsumowując, hipoteza że prawdobodobieństwo, że w firmie pracuje kobieta wynosi 0.5 jest nieprawdziwa.

### 2. Prawdopodbieństwo, że pracownik jest zadowolony ze swojego wynagrodzenia w pierwszym badanym okresie jest większe bądź równe 0.7.

Zweryfikowaliśmy hipotezę, że prawdobodobieństwo, że pracownik jest zadowolony ze swojego wynagrodzenia w pierwszym badanym okresie jest większe bądź równe 0.7, co było naszą hipotezą zerową. Podobnie jak w pierwszym teście przyjęto poziom ufności 0.95 i zweryfikowaliśmy prawdziwość hipotezy zerowej na podstawie przedziału ufności oraz p-wartości. Wyniki zostały wyświetlone poniżej.

```{r}
#| warning: false
sum_zadow <- length(data$CZY_ZADOW[data$CZY_ZADOW == 1])
test_2 <- binom.test(sum_zadow, nrow(data), p = 0.7, alternative = "less")
cat('P - wartość wynosi:', test_2$p.value, 
    ', przedział ufności jest postaci: [',
    test_2$conf.int, ']')
```

Test dał nam p-wartość mniejszą od zakładanego poziomu istotności, co sugeruje by odrzucić hipotezę zerową. Co więcej możemy zauważyć, że p \> = 0.7 jest poza przedziałem ufności, co podkreśla słuszność odrzucenia hipotezy zerowej na rzecz alternatywnej.

### 3. Prawdopodobieństwo, że kobieta pracuje na stanowisku menedżerskim jest równe prawdopodobieństwu, że meżczyzna pracuje na stanowisku menedżerskim.

Przeprowadzimy testy proporcji z poprawką na ciągłość i bez aby określić prawdziwość hipotezy zerowej że prawdopodobienstwo, że kobieta pracuje na stanowisku menedżerskim jest równe prawdopodobieństwu, że mężczyzna pracuje na stanowisku menedzerskim. Hipoteza alternatywna mówi, że te prawdopodobieństwa nie są równe. Wykonamy testy na poziomie ufności 0.95. Zweryfikujemy hipoteze zerową dzięki p-wartości. Wyniki testu są umieszczone w poniższej tabeli.

```{r}
#| warning: false
sum_menadzer_woman <- length(data$PLEC[data$PLEC == "K" & data$CZY_KIER == 'Tak'])
sum_menadzer_man <- length(data$PLEC[data$PLEC == "M" & data$CZY_KIER == 'Tak'])

test_3_con <- prop.test(c(sum_menadzer_woman, sum_menadzer_man), 
                        c(length(data$PLEC[data$PLEC == "K"]), 
                          length(data$PLEC[data$PLEC == "M"])), 
                        alternative = "two.sided", correct = TRUE)

test_3_ucon <- prop.test(c(sum_menadzer_woman, sum_menadzer_man), 
                        c(length(data$PLEC[data$PLEC == "K"]), 
                          length(data$PLEC[data$PLEC == "M"])), 
                        alternative = "two.sided", correct = FALSE)

test_3_df <- data.frame('Testy' = c('Test z poprawką na ciągłość', 
                                    'Test bez poprawki na ciągłość'), 
           'P-wartość' = c(test_3_con$p.value, test_3_ucon$p.value))

knitr::kable(test_3_df)
```

Zauważmy, że dla obu testów p-wartość jest większa niż poziom istotności $\alpha = 0.05$, zatem nie ma podstaw do odrzucenia hipotezy zerowej.

### 4. Prawdopodobieństwo, że kobieta jest zadowolona ze swojego wynagrodzenia w pierwszym badanym okresie jest równe prawdopodobieństwu, że mężczyzna jest zadowolony ze swojego wynagrodzenia w pierwszym badanym okresie.

Będziemy testować hipotezę zerową że prawdopodobieństwo, że kobieta jest zadowolona ze swojego wynagrodzenia w pierwszym badanym okresie jest równe prawdopodobieństwu, że mężczyzna jest zadowolony ze swojego wynagrodzenia w pierwszym badanym okresie przeciw hipotezie alteratywnej, że te prawdopodobieństwa nie są równe. Przyjmujemy poziom ufności 0.95. Będziemy brali głównie pod uwagę p-wartość. Wyniki zostały umieszczone w tabeli poniżej.

```{r}
#| warning: false
sum_zadow_woman <- length(data$PLEC[data$PLEC == "K" & data$CZY_ZADOW == 1])
sum_zadow_man <- length(data$PLEC[data$PLEC == "M" & data$CZY_ZADOW == 1])

test_4_con <- prop.test(c(sum_zadow_woman, sum_zadow_man), 
                        c(length(data$PLEC[data$PLEC == "K"]), 
                          length(data$PLEC[data$PLEC == "M"])), 
                        alternative = "two.sided", correct = TRUE)

test_4_ucon <- prop.test(c(sum_zadow_woman, sum_zadow_man), 
                         c(length(data$PLEC[data$PLEC == "K"]), 
                           length(data$PLEC[data$PLEC == "M"])), 
                         alternative = "two.sided", correct = FALSE)

test_4_df <- data.frame('Testy' = c('Test z poprawką na ciągłość', 
                                    'Test bez poprawki na ciągłość'), 
                        'P-wartość' = c(test_4_con$p.value, test_4_ucon$p.value))

knitr::kable(test_4_df)
```

Zauważmy, że dla obu testów p-wartość jest większa niż poziom istotności $\alpha = 0.05$, zatem nie podstaw do odrzucenia hipotezy zerowej.

### 5. Prawdopodobieństwo, że kobieta pracuje w dziale obsługi kadrowo-płacowej jest większe lub równe prawdopodobieństwu, że mężczyzna pracuje w dziale obsługi kadrowo- płacowej.

Wykonaliśmy test proporcji aby zweryfikować hipotezę zerową że prawdopodobieństwo, że kobieta pracuje w dziale obsługi kadrowo-płacowej jest większe lub równe prawdopodobieństwu, że mężczyzna pracuje w dziale obsługi kadrowo- płacowej. Hipotezą alternatywną dla tej hipotezy zerowej jest prawdopodobieństwo, że kobieta pracuje w dziale obsługi kadrowo-płacowej jest mniejsze od prawdopodobieństwa, że mężczyzna pracuje w dziale obsługi kadrowo- płacowej. Test wykonaliśmy na poziomie ufności 0.95. Wyniki przedstawiliśmy w tabeli poniżej.

```{r}
#| warning: false
sum_hr_woman <- length(data$PLEC[data$PLEC == "K" & data$DZIAL == 'HR'])
sum_hr_man <- length(data$PLEC[data$PLEC == "M" & data$DZIAL == 'HR'])

test_5_con <- prop.test(c(sum_hr_woman, sum_hr_man), 
                        c(length(data$PLEC[data$PLEC == "K"]), 
                          length(data$PLEC[data$PLEC == "M"])), 
                        alternative = "less", correct = TRUE)

test_5_ucon <- prop.test(c(sum_hr_woman, sum_hr_man), 
                         c(length(data$PLEC[data$PLEC == "K"]), 
                           length(data$PLEC[data$PLEC == "M"])), 
                         alternative = "less", correct = FALSE)

test_5_df <- data.frame('Testy' = c('Test z poprawką na ciągłość', 
                                    'Test bez poprawki na ciągłość'), 
                        'P-wartość' = c(test_5_con$p.value, test_5_ucon$p.value))
knitr::kable(test_5_df)
```

Zauważmy, że dla obu testów p-wartość jest mniejsza niż poziom istotności $\alpha =0.05$, zatem należy odrzucić hipotezę zerową.

## **5.2. Zadanie 12.**

#### Wyznacz symulacyjnie moc testu dokładnego oraz moc testu asymptotycznego w przypadku weryfikacji hipotezy zerowej $H_0: p = 0.9$ przeciwko $H_1: p \neq 0.9$ przyjmując wartość $1-\alpha = 0.95$. Uwzględnij różne wartości alternatyw i różne rozmiary próby. Sformułuj wnioski.

Do porównania wyznaczonych wartości funkcji mocy zastosowaliśmy poniższą symulacje Monte Carlo:

1.  Generujemy realizację przedziału $\mathcal{B}(n,p)$
2.  Dla wygenerowanej realizacji wykonujemy testy, które zwracają nam odpowiednie przedziały ufności, służące do określenia przedziałów odrzucenia naszej $H_0$.
3.  Obliczamy moc testu, czyli $\frac{\text{#}\{\text{Ilość odrzuconych przypadków}\}}{MCS}$
4.  Symulacje wykonujemy dla $p \in\{0.01, ..., 0.99\}$, $n \in\{30,100,1000\}$ $MCS = 1000$ razy.

Wyniki symulacji przedstawiliśmy oczywiście na wykresach.

### $n=30$

```{r}
#| warning: false
p_s_tests <-  seq(from=0.01, to= 0.99, length.out = 98)
pwr_binom_test_30 = rep(0,98)
pwr_prop_test_corrected_30 = rep(0,98)
pwr_prop_test_30 = rep(0,98)
for (k in 1:98) {
  temp_binom = 0 
  temp_prop_corrected = 0
  temp_prop = 0
  for (i in 1:1000) {
    sample_binom = rbinom(n = 100, size = 30, prob = p_s_tests[k])
    ci_binom = binom.test(sum(sample_binom),n = 100*30, p = .9)$conf.int
    if (!(ci_binom[1] < 0.9 & 0.9 < ci_binom[2])) {
      temp_binom = temp_binom + 1
    }
    
    
    ci_prop_corrected = prop.test(sum(sample_binom),n = 100*30, p = .9)$conf.int
    if (!(ci_prop_corrected[1] < 0.9 & 0.9 < ci_prop_corrected[2])) {
      temp_prop_corrected = temp_prop_corrected + 1
    }
    
    
    ci_prop = prop.test(sum(sample_binom),n = 100*30, p = .9, correct = FALSE)$conf.int
    if (!(ci_prop[1] < 0.9 & 0.9 < ci_prop[2])) {
      temp_prop = temp_prop + 1
    }
    
  }
  pwr_binom_test_30[k] <- temp_binom/1000
  pwr_prop_test_corrected_30[k] <- temp_prop_corrected/1000
  pwr_prop_test_30[k] <- temp_prop/1000
}
plot(p_s_tests,pwr_binom_test_30, type = "l", frame = FALSE, pch = 19,
     col = "red",main="         Porównanie mocy testów H0: p=0.9, 
        n = 30, długość próbki = 100, 1000 MCS", xlab = "p", ylab = "moc testu", 
     lty = 1, lwd = 2)

lines(p_s_tests, pwr_prop_test_corrected_30, pch = 23, col = "blue", type = "l", 
      lty = 2, lwd = 2)

lines(p_s_tests, pwr_prop_test_30, pch = 18, col = "green", type = "b", 
      lty = 3, lwd = 2)

legend("left", legend = c("binom.test(_)", "prop.test(_)", "prop.test(_, correct = FALSE"),
       col = c("red", "blue", "green"), lty = 1:3, cex = 0.8)

```

Za pomocą analogicznego kodu ilustrujemy moc testu dla pozostałych wartości $n$

### $n = 100$

```{r}
#| warning: false
#| echo: false
pwr_binom_test_100 = rep(0,98)
pwr_prop_test_corrected_100 = rep(0,98)
pwr_prop_test_100 = rep(0,98)
for (k in 1:98) {
  temp_binom = 0 
  temp_prop_corrected = 0
  temp_prop = 0
  for (i in 1:1000) {
    sample_binom = rbinom(n = 100, size = 100, prob = p_s_tests[k])
    ci_binom = binom.test(sum(sample_binom),n = 100*100, p = .9)$conf.int
    if (!(ci_binom[1] < 0.9 & 0.9 < ci_binom[2])) {
      temp_binom = temp_binom + 1
    }
    
    
    ci_prop_corrected = prop.test(sum(sample_binom),n = 100*100, p = .9)$conf.int
    if (!(ci_prop_corrected[1] < 0.9 & 0.9 < ci_prop_corrected[2])) {
      temp_prop_corrected = temp_prop_corrected + 1
    }
    
    
    ci_prop = prop.test(sum(sample_binom),n = 100*100, p = .9, correct = FALSE)$conf.int
    if (!(ci_prop[1] < 0.9 & 0.9 < ci_prop[2])) {
      temp_prop = temp_prop + 1
    }
    
  }
  pwr_binom_test_100[k] <- temp_binom/1000
  pwr_prop_test_corrected_100[k] <- temp_prop_corrected/1000
  pwr_prop_test_100[k] <- temp_prop/1000
}
plot(p_s_tests,pwr_binom_test_100, type = "l", frame = FALSE, pch = 19,
     col = "red",main="         Porównanie mocy testówm H0: p=0.9, 
        n = 100, długość próbki = 100, 1000 MCS", xlab = "p", ylab = "moc testu", 
     lty = 1, lwd = 2)

lines(p_s_tests, pwr_prop_test_corrected_100, pch = 23, col = "blue", type = "l", 
      lty = 2, lwd = 2)

lines(p_s_tests, pwr_prop_test_100, pch = 18, col = "green", type = "b", 
      lty = 3, lwd = 2)

legend("left", legend = c("binom.test(_)", "prop.test(_)", "prop.test(_, correct = FALSE"),
       col = c("red", "blue", "green"), lty = 1:3, cex = 0.8)

```

### $n=1000$

```{r}
#| warning: false
#| echo: false
pwr_binom_test_1000 = rep(0,98)
pwr_prop_test_corrected_1000 = rep(0,98)
pwr_prop_test_1000 = rep(0,98)
for (k in 1:98) {
  temp_binom = 0 
  temp_prop_corrected = 0
  temp_prop = 0
  for (i in 1:1000) {
    sample_binom = rbinom(n = 100, size = 1000, prob = p_s_tests[k])
    ci_binom = binom.test(sum(sample_binom),n = 100*1000, p = .9)$conf.int
    if (!(ci_binom[1] < 0.9 & 0.9 < ci_binom[2])) {
      temp_binom = temp_binom + 1
    }
    
    
    ci_prop_corrected = prop.test(sum(sample_binom),n = 100*1000, p = .9)$conf.int
    if (!(ci_prop_corrected[1] < 0.9 & 0.9 < ci_prop_corrected[2])) {
      temp_prop_corrected = temp_prop_corrected + 1
    }
    
    
    ci_prop = prop.test(sum(sample_binom),n = 100*1000, p = .9, correct = FALSE)$conf.int
    if (!(ci_prop[1] < 0.9 & 0.9 < ci_prop[2])) {
      temp_prop = temp_prop + 1
    }
    
  }
  pwr_binom_test_1000[k] <- temp_binom/1000
  pwr_prop_test_corrected_1000[k] <- temp_prop_corrected/1000
  pwr_prop_test_1000[k] <- temp_prop/1000
}
plot(p_s_tests,pwr_binom_test_1000, type = "l", frame = FALSE, pch = 19,
     col = "red",main="         Porównanie mocy testówm H0: p=0.9, 
        n = 1000, długość próbki = 100, 1000 MCS", xlab = "p", ylab = "moc testu", 
     lty = 1, lwd = 2)

lines(p_s_tests, pwr_prop_test_corrected_1000, pch = 23, col = "blue", type = "l", 
      lty = 2, lwd = 2)

lines(p_s_tests, pwr_prop_test_1000, pch = 18, col = "green", type = "b", 
      lty = 3, lwd = 2)

legend("left", legend = c("binom.test(_)", "prop.test(_)", "prop.test(_, correct = FALSE"),
       col = c("red", "blue", "green"), lty = 1:3, cex = 0.8)
```

Podsumowując porównanie, wszystkie testy są zgodne, nie da się wybrać testu jednostajnie najmocniejszego. Dodatkowo, możemy zauważyć węższy "peak" w wykresach mocy testu przy zwiększaniu ilości prób Bernoulliego, czyli parametru $n$ rozkładu.

# 6. Źródła i literatura

\[1\] Sheldon M. Ross, *Simulation Fourth Edition,* Elsevier.

\[2\] Fishman,George S., *Sampling from the Multinomial Distribution on a Computer*, 1978.
